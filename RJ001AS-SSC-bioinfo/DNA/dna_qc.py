#!/usr/bin/env python3
from statistics import mean
from decimal import Decimal
import os
import sys
import argparse
import re
import itertools
REAL_DIR = os.path.dirname(os.path.realpath(__file__))
sys.path.append(os.path.join(os.path.dirname(REAL_DIR), "common"))
import tools


def parse_arguments():
    parser = argparse.ArgumentParser(description="gather sample's qc metrics from multi files")
    parser.add_argument("--sample_name", dest="sample_name",
                        required=True, help="")
    parser.add_argument("--raw_fqstat_file", dest="raw_fqstat_file", required=True,
                        help="qc stat file for raw fastq that has not been cleaned")
    parser.add_argument("--clean_fqstat_file", dest="clean_fqstat_file", required=True,
                        help="path to qc file for cleaned fastq that has been cleaned")
    parser.add_argument("--sort_flagstat", dest="sort_flagstat", required=True,
                        help="flagstat file for sorted bam")
    parser.add_argument('--sort_cover_flagstat', dest='sort_cover_flagstat', required=True,
                        help="path to flagstat file for sorted bam that has been intersected with target bed")
    parser.add_argument("--insert_metrics", dest='insert_metrics',
                        required=True,  help="insert size metrics file output by picard")
    parser.add_argument('--depth_base_file', dest='depth_base_file',
                        required=True, help="depth base file")
    parser.add_argument('--depth_summary_file', dest='depth_summary_file',
                        required=True, help="depth summary file")
    parser.add_argument('--out_file', dest='out_file',
                        required=True, help="out path")
    return parser.parse_args()


def main():
    args = parse_arguments()
    sample_name = args.sample_name
    raw_fqstat_file = os.path.abspath(args.raw_fqstat_file)
    clean_fqstat_file = os.path.abspath(args.clean_fqstat_file)
    sort_flagstat = os.path.abspath(args.sort_flagstat)
    sort_cover_flagstat = os.path.abspath(args.sort_cover_flagstat)
    insert_metrics_file = os.path.abspath(args.insert_metrics)
    depth_base_file = os.path.abspath(args.depth_base_file)
    depth_summary_file = os.path.abspath(args.depth_summary_file)
    out_file = os.path.abspath(args.out_file)
    qc_summary = DNAQcSummary(
        sample_name=sample_name,
        raw_fqstat_file=raw_fqstat_file,
        clean_fqstat_file=clean_fqstat_file,
        sort_flagstat=sort_flagstat,
        sort_cover_flagstat=sort_cover_flagstat,
        insertsize_metrics=insert_metrics_file,
        depth_base_file=depth_base_file,
        depth_summary_file=depth_summary_file
    )
    qc_summary.write_qc_summary_file(out_file)


class DNAQcSummary(object):
    # headers for output file
    headers = ["Sample_Name", "Raw_Data(Mb)", "Raw_Reads", "Clean_Data(Mb)", "Clean_Reads", "Raw_Q30", "Clean_Q30", "GC_Content", "Mapped_Ratio", "Insert_Size",
               "On_Target_Ratio", "Mean_Depth", "Median_Depth", "Greater_1X", "Greater_Min", "Greater_20Pct", "Greater_Mean", "Warning", "Status"]

    # threshold for metrics, if lower than the specified value, output warning message in the warnings column
    warning_threshold = {
        "raw_q30_ratio": 80,
        "map_ratio": 90,
        "mean_depth": 20000,
        "greater_pct20": 70
    }

    def __init__(self, sample_name, raw_fqstat_file, clean_fqstat_file,
                 sort_flagstat, sort_cover_flagstat, insertsize_metrics,
                 depth_base_file, depth_summary_file) -> None:
        """initiate an instance of <class QcSummary>, 
            read all kinds of qc metrics file to member variables,
            and check threshold.

        Args:
            sample_name (string): sample name
            raw_fqstat_file (string): path to fqstat file of raw fastq
            clean_fqstat_file (string): path to fqstat file of cleaned fastq
            sort_flagstat (string): path to flagstat file of sorted bam
            sort_cover_flagstat (string): path to flagstat file of sorted that has been intersected with target bed
            insertsize_metrics (string): path to insert size metrics file that is generated by picard
            depth_base_file (string): path to depth base file, containing depth of all bases
            depth_summary_file (string): path to depth summary file
        """
        self.sample_name = sample_name
        raw_q30, raw_basenum, readnum, gccontent = self.parse_fqstat_file(
            raw_fqstat_file)
        clean_q30, clean_basenum, clean_readnum, clean_gccontent = self.parse_fqstat_file(
            clean_fqstat_file)
        self.raw_q30_ratio = self.get_mean(raw_q30)
        self.clean_q30_ratio = self.get_mean(clean_q30)
        self.raw_data_mb = int(round(sum(raw_basenum) / 1000000, 0))
        self.clean_data_mb = int(round(sum(clean_basenum) / 1000000, 0))
        self.raw_reads = round(sum(readnum), 2)
        self.clean_reads = sum(clean_readnum)
        self.clean_reads_mb = self.format_float(round(sum(clean_readnum) / 1000000.0, 2))
        self.raw_gc_content = self.get_mean(gccontent)
        self.clean_gc_content = self.get_mean(clean_gccontent)
        self.map_ratio, self.total_map_num = self.load_flagstat_file(
            sort_flagstat)
        capture_map_ratio, capture_map_num = self.load_flagstat_file(
            sort_cover_flagstat)
        self.capture_ratio = self.format_float(round(
            float(capture_map_num) / float(self.total_map_num) * 100, 2))
        self.insert_size = self.load_insert_metrics(insertsize_metrics)
        self.depth_base_file = depth_base_file
        self.depth_summary_file = depth_summary_file
        self.greater_1x, self.greater_pct20, self.greater_min, self.greater_mean, \
            self.mean_depth, self.median_depth, self.depth50 = self.get_depth_summary()
        self.check_threshold()
        
    @staticmethod
    def format_float(float_digit):
        format_digit = Decimal(float_digit).quantize(Decimal("0.00"))
        return format_digit
        
    @staticmethod
    def get_mean(value_list):
        value_mean  = Decimal(mean(value_list)).quantize(Decimal("0.00"))
        return value_mean

    def write_qc_summary_file(self, out_file):
        fout = open(out_file, 'w')
        fout.write("\t".join(self.headers) + "\n")
        summary_dict = dict()
        summary_dict["Sample_Name"] = self.sample_name
        summary_dict["Raw_Data(Mb)"] = self.raw_data_mb
        summary_dict["Raw_Reads"] = self.raw_reads
        summary_dict["Clean_Data(Mb)"] = self.clean_data_mb
        summary_dict["Clean_Reads"] = self.clean_reads
        summary_dict["Raw_Q30"] = self.raw_q30_ratio
        summary_dict["Clean_Q30"] = self.clean_q30_ratio
        summary_dict["GC_Content"] = self.clean_gc_content
        summary_dict["Mapped_Ratio"] = self.map_ratio
        summary_dict["Insert_Size"] = self.insert_size
        summary_dict["On_Target_Ratio"] = self.capture_ratio
        summary_dict["Mean_Depth"] = self.mean_depth
        summary_dict["Median_Depth"] = self.median_depth
        summary_dict["Greater_1X"] = self.greater_1x
        summary_dict["Greater_Min"] = self.greater_min
        summary_dict["Greater_20Pct"] = self.greater_pct20
        summary_dict["Greater_Mean"] = self.greater_mean
        summary_dict["Warning"] = self.warning_msg
        summary_dict["Status"] = self.status
        fout.write("\t".join([str(summary_dict[h]) for h in self.headers]) + "\n")
        fout.close()

    def check_threshold(self):
        """according the threshold provides, check four metrics value, 
        If all thresholds meet, warning message is NA and status is Pass
        Otherwise, warning message will be the no 
        """
        self.warnings = []
        if self.raw_q30_ratio < self.warning_threshold["raw_q30_ratio"]:
            self.warnings.append(f"Raw.Q30.Ratio={self.raw_q30_ratio}")
        if self.map_ratio < self.warning_threshold["map_ratio"]:
            self.warnings.append(f"Map.Ratio={self.map_ratio}")
        if self.mean_depth < self.warning_threshold["mean_depth"]:
            self.warnings.append(f"Mean.Depth={self.mean_depth}")
        if self.greater_pct20 < self.warning_threshold["greater_pct20"]:
            self.warnings.append(f"Greater_20Pct={self.greater_pct20}")
        if len(self.warnings) >= 1:
            self.warning_msg = ";".join(self.warnings)
            self.status = "Fail"
        else:
            self.warning_msg = "NA"
            self.status = "Pass"

    def get_depth_summary(self):
        depth_list = self.parse_depth_base_file(self.depth_base_file)
        mean_depth, median_depth, depth50 = self.parse_depth_summary_file(
            self.depth_summary_file)

        def greater(line_depth):
            n = 0
            for site_depth in depth_list:
                if int(site_depth) >= line_depth:
                    n += 1
            try:
                greater_ratio = Decimal(float(n) / float(len(depth_list)) * 100).quantize(Decimal("0.00"))
            except Exception as e:
                return Decimal(0).quantize(Decimal("0.00"))
            return greater_ratio
        greater_1x = greater(1)
        greater_pct20 = greater(0.2 * mean_depth)
        greater_min = greater(2000)
        greater_mean = greater(mean_depth)
        return greater_1x, greater_pct20, greater_min, greater_mean, mean_depth, median_depth, depth50

    def load_flagstat_file(self, flagstat_file):
        """parse flagstat file, that is generated by command `samtools flagstat`

        Args:
            flagstat_file (string): path to sample's flagstat file

        Returns:
            ratio(float): ratio of mapped reads
            mapped_num(int): number of mapped reads
        """
        total_num = 0
        mapped_num = 0
        with open(flagstat_file, 'r') as finp:
            for line in finp.readlines():
                line = line.strip("\n")
                rest = re.match(
                    r'(\d+)\s\+\s\d+\sin\stotal\s\(QC-passed\sreads\s\+\sQC-failed\sreads\)', line)
                if rest is not None:
                    total_num = int(rest.group(1))
                rest = re.match(r'(\d+)\s\+\s\d+\smapped*', line)
                if rest is not None:
                    mapped_num = int(rest.group(1))
        ratio = self.format_float(round(float(mapped_num * 100) / float(total_num), 2))
        return ratio, mapped_num

    @staticmethod
    def parse_fqstat_file(fqstat_file):
        """parse fqstat file generated by reseqtools to get several metrics value for fastq
            the fqstat file can be for raw fastq or cleaned fastq

        Args:
            fqstat_file (string): path to fqstat 

        Returns:
            q30 (float): Q30 percent of the data
            basenum (float): base yeild of the data
            readnum (float): reads number of the data
            gccontent (float): gc content percent of the data
        """
        q30 = list()
        basenum = list()
        readnum = list()
        gccontent = list()
        with open(fqstat_file, 'r') as finp:
            for line in finp.readlines():
                line = line.strip("\n")
                rest = re.match(r'^#BaseQ:20--30.*>Q30:\s(.*)%', line)
                if rest is not None:
                    q30.append(float(rest.group(1)))
                rest = re.match(r'^#ReadNum:.*BaseNum:\s(\d+)', line)
                if rest is not None:
                    basenum.append(float(rest.group(1)))
                rest = re.match(r'^#ReadNum:\s(\d+)', line)
                if rest is not None:
                    readnum.append(int(rest.group(1)))
                rest = re.match(r'^#GC%:\s(\d+)', line)
                if rest is not None:
                    gccontent.append(float(rest.group(1)))
        return q30, basenum, readnum, gccontent

    @staticmethod
    def parse_depth_base_file(depth_base_file):
        """parse <out_dir>TMP/<sample_name>_sort_DepthOfCoverage

        Args:
            summary_file (string): path to the summary file

        Returns:
            list: a list file contains sequencing depth value of all sites
        """
        depth_list = list()
        with open(depth_base_file, 'r') as finp:
            headers = finp.readline().strip("\n").split("\t")
            for line in finp:
                cols = line.strip("\n").split("\t")
                site_depth = cols[3]
                depth_list.append(site_depth)
                # site_depth_dict = dict(zip(headers, cols))
                # depth_list.append(site_depth_dict)
        return depth_list

    @staticmethod
    def load_insert_metrics(metrics_file):
        """parse insert metrics file, get median insert size of sample sequencing data

        Args:
            metrics_file (string): path to sample's insert metrics file, that is generated by picard

        Returns:
            string: value of median insert size of sequencing data
        """
        with open(metrics_file, 'r') as finp:
            lines = finp.readlines()
            lines = map(lambda x: x.strip("\n"), lines)
            datalines = list(filter(lambda x: '#' not in x, lines))
            datalines = list(filter(lambda x: x != "", datalines))
            keys = datalines[0].split("\t")
            values = datalines[1].split("\t")
            metrics_dict = dict(itertools.zip_longest(keys, values))
            return metrics_dict["MEDIAN_INSERT_SIZE"]

    @staticmethod
    def parse_depth_summary_file(depth_summary_file):
        """parse <out_dir>/TMP/<sample_name>_sort_DepthOfCoverage.sample_summary

        Args:
            depth_summary_file (string): path to the depth of coverage summary file

        Returns:
            mean_depth (float): mean depth of sequencing data
            median_depth (float): median depth of sequencing data
            depth50 (float): ratio of bases with depth above 500
        """
        with open(depth_summary_file, 'r') as finp:
            lines = finp.readlines()
            lines = list(map(lambda x: x.strip('\n'), lines))
            keys = lines[0].split("\t")
            values = lines[1].split("\t")
            summary_dict = dict(itertools.zip_longest(keys, values))
            mean_depth =  int(round(float(summary_dict["mean"]), 0))
            median_depth = int(summary_dict["granular_median"])
            depth50 = float(summary_dict["%_bases_above_500"])
            return mean_depth, median_depth, depth50


if __name__ == '__main__':
    main()